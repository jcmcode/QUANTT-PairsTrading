{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 â€” Multi-Algorithm Comparison\n",
    "\n",
    "Runs KMeans and DBSCAN alongside OPTICS on the combined universe.\n",
    "Identifies consensus pairs and runs permutation tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T01:36:30.262635Z",
     "iopub.status.busy": "2026-02-24T01:36:30.262333Z",
     "iopub.status.idle": "2026-02-24T01:36:31.766739Z",
     "shell.execute_reply": "2026-02-24T01:36:31.766311Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join('..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN, OPTICS\n",
    "\n",
    "from config import DEFAULT_CONFIG\n",
    "from signals.detection import compute_co_cluster_freq\n",
    "from validation.pair_validation import feature_shuffle_permutation_test\n",
    "from screener.universe import load_cached_universe\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T01:36:31.768071Z",
     "iopub.status.busy": "2026-02-24T01:36:31.767935Z",
     "iopub.status.idle": "2026-02-24T01:36:31.785119Z",
     "shell.execute_reply": "2026-02-24T01:36:31.784744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_df: 201498 rows\n",
      "OPTICS pairs: 7836\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join('..', 'data', 'combined')\n",
    "\n",
    "_, _, sector_map = load_cached_universe('combined')\n",
    "\n",
    "with open(os.path.join(data_dir, 'ts_df.pkl'), 'rb') as f:\n",
    "    ts_df = pickle.load(f)\n",
    "with open(os.path.join(data_dir, 'pair_co_cluster_freq.pkl'), 'rb') as f:\n",
    "    optics_freq = pickle.load(f)\n",
    "with open(os.path.join(data_dir, 'cluster_history.pkl'), 'rb') as f:\n",
    "    optics_ch = pickle.load(f)\n",
    "\n",
    "print(f\"ts_df: {ts_df.shape[0]} rows\")\n",
    "print(f\"OPTICS pairs: {len(optics_freq)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run KMeans & DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T01:36:31.800854Z",
     "iopub.status.busy": "2026-02-24T01:36:31.800744Z",
     "iopub.status.idle": "2026-02-24T01:36:44.773069Z",
     "shell.execute_reply": "2026-02-24T01:36:44.772670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running kmeans...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1419 snapshots, 10011 pairs, noise=0.0%\n",
      "Running dbscan...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1419 snapshots, 10011 pairs, noise=19.8%\n"
     ]
    }
   ],
   "source": [
    "features = list(DEFAULT_CONFIG.features.features_to_cluster)\n",
    "n_clusters_kmeans = 8  # larger universe needs more clusters\n",
    "\n",
    "def run_alt_clustering(ts_df, features, algo='kmeans'):\n",
    "    \"\"\"Run KMeans or DBSCAN across all timestamps.\"\"\"\n",
    "    timestamps = ts_df.index.get_level_values('Datetime').unique()\n",
    "    results = []\n",
    "    for ts in timestamps:\n",
    "        try:\n",
    "            snapshot = ts_df.xs(ts, level='Datetime')[features].dropna()\n",
    "        except KeyError:\n",
    "            continue\n",
    "        if len(snapshot) < 5:\n",
    "            continue\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(snapshot.values)\n",
    "        pca = PCA(n_components=0.90)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        if algo == 'kmeans':\n",
    "            model = KMeans(n_clusters=min(n_clusters_kmeans, len(snapshot) - 1),\n",
    "                          n_init=10, random_state=42)\n",
    "        elif algo == 'dbscan':\n",
    "            model = DBSCAN(eps=1.5, min_samples=3)\n",
    "        model.fit(X_pca)\n",
    "        n_c = len(set(model.labels_)) - (1 if -1 in model.labels_ else 0)\n",
    "        if n_c < 1:\n",
    "            continue\n",
    "        for ticker, label in zip(snapshot.index.tolist(), model.labels_):\n",
    "            results.append({'Ticker': ticker, 'Datetime': ts, 'Cluster_ID': int(label)})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "algo_freqs = {'optics': optics_freq}\n",
    "for algo_name in ['kmeans', 'dbscan']:\n",
    "    print(f\"Running {algo_name}...\")\n",
    "    ch = run_alt_clustering(ts_df, features, algo=algo_name)\n",
    "    if ch.empty:\n",
    "        print(f\"  No valid clusters\")\n",
    "        continue\n",
    "    freq, _ = compute_co_cluster_freq(ch)\n",
    "    noise_rate = (ch['Cluster_ID'] == -1).mean()\n",
    "    print(f\"  {ch['Datetime'].nunique()} snapshots, {len(freq)} pairs, noise={noise_rate:.1%}\")\n",
    "    algo_freqs[algo_name] = freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Consensus Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T01:36:44.774284Z",
     "iopub.status.busy": "2026-02-24T01:36:44.774210Z",
     "iopub.status.idle": "2026-02-24T01:36:44.781080Z",
     "shell.execute_reply": "2026-02-24T01:36:44.780731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optics top-20: ['AAL-DAL', 'AAL-UAL', 'AMAT-LRCX', 'BP-XOM', 'CIFR-HUT']...\n",
      "kmeans top-20: ['AAL-DAL', 'BP-SHEL', 'CNQ-CVE', 'CNQ-SU', 'COP-DVN']...\n",
      "dbscan top-20: ['CNQ-COP', 'CNQ-SHEL', 'CNQ-XOM', 'COP-CVX', 'COP-DVN']...\n",
      "\n",
      "Consensus (in all 3 algos' top-20): 3\n",
      "  COP-DVN                   Energy / Energy  [INTRA]\n",
      "  CVX-XOM                   Energy / Energy  [INTRA]\n",
      "  SU-XOM                    Energy / Energy  [INTRA]\n"
     ]
    }
   ],
   "source": [
    "top_n = 20\n",
    "algo_top_sets = {}\n",
    "for algo_name, freq in algo_freqs.items():\n",
    "    top_pairs = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    pair_strs = {f\"{a}-{b}\" for (a, b), _ in top_pairs}\n",
    "    algo_top_sets[algo_name] = pair_strs\n",
    "    print(f\"{algo_name} top-{top_n}: {sorted(pair_strs)[:5]}...\")\n",
    "\n",
    "consensus = set.intersection(*algo_top_sets.values()) if len(algo_top_sets) >= 2 else set()\n",
    "print(f\"\\nConsensus (in all {len(algo_top_sets)} algos' top-{top_n}): {len(consensus)}\")\n",
    "for pair in sorted(consensus):\n",
    "    # Tag with sector info\n",
    "    parts = pair.split('-', 1)\n",
    "    if len(parts) == 2:\n",
    "        sa = sector_map.get(parts[0], '?')\n",
    "        sb = sector_map.get(parts[1], '?')\n",
    "        ptype = 'INTRA' if sa == sb else 'CROSS'\n",
    "        print(f\"  {pair:25s} {sa} / {sb}  [{ptype}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Permutation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T01:36:44.782086Z",
     "iopub.status.busy": "2026-02-24T01:36:44.782021Z",
     "iopub.status.idle": "2026-02-24T01:38:01.125188Z",
     "shell.execute_reply": "2026-02-24T01:38:01.124836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running permutation test (30 permutations, 80 sampled timestamps)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction significant (Z>1.96): 32.4%\n",
      "\n",
      "Top 10 significant pairs:\n",
      "  PBR-PBR-A: Z=38.59  [INTRA]\n",
      "  AAL-DAL: Z=38.19  [INTRA]\n",
      "  AAL-UAL: Z=36.83  [INTRA]\n",
      "  DAL-UAL: Z=34.03  [INTRA]\n",
      "  HAL-SLB: Z=32.08  [INTRA]\n",
      "  KMI-WMB: Z=30.65  [INTRA]\n",
      "  DVN-OXY: Z=27.04  [INTRA]\n",
      "  CVX-XOM: Z=26.86  [INTRA]\n",
      "  SU-XOM: Z=25.86  [INTRA]\n",
      "  AMAT-LRCX: Z=25.13  [INTRA]\n"
     ]
    }
   ],
   "source": [
    "optics_params = {\n",
    "    'min_samples': DEFAULT_CONFIG.clustering.min_samples,\n",
    "    'xi': DEFAULT_CONFIG.clustering.xi,\n",
    "    'min_cluster_size': DEFAULT_CONFIG.clustering.min_cluster_size,\n",
    "}\n",
    "total_windows = optics_ch['Datetime'].nunique()\n",
    "\n",
    "print(\"Running permutation test (30 permutations, 80 sampled timestamps)...\")\n",
    "perm = feature_shuffle_permutation_test(\n",
    "    ts_df, features, optics_params, optics_freq, total_windows,\n",
    "    n_permutations=30, n_sample_timestamps=80,\n",
    ")\n",
    "print(f\"Fraction significant (Z>1.96): {perm['fraction_significant']:.1%}\")\n",
    "\n",
    "sig_pairs = {p: z for p, z in perm['pair_zscores'].items() if z > 1.96}\n",
    "top_sig = sorted(sig_pairs.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "print(f\"\\nTop 10 significant pairs:\")\n",
    "for (a, b), z in top_sig:\n",
    "    sa = sector_map.get(a, '?')\n",
    "    sb = sector_map.get(b, '?')\n",
    "    ptype = 'INTRA' if sa == sb else 'CROSS'\n",
    "    print(f\"  {a}-{b}: Z={z:.2f}  [{ptype}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T01:38:01.127288Z",
     "iopub.status.busy": "2026-02-24T01:38:01.127196Z",
     "iopub.status.idle": "2026-02-24T01:38:01.134185Z",
     "shell.execute_reply": "2026-02-24T01:38:01.133781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_dir, 'consensus_pairs.pkl'), 'wb') as f:\n",
    "    pickle.dump(consensus, f)\n",
    "with open(os.path.join(data_dir, 'permutation_results.pkl'), 'wb') as f:\n",
    "    pickle.dump(perm, f)\n",
    "print(\"Saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
